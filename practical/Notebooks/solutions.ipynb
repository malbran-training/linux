{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux for Bioinformatics\n",
    "No exercises in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Linux\n",
    "\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "\n",
    "`find . -type d`\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Navigate to the basic directory with:\n",
    "\n",
    "`cd ~/course_data/linux/data/basic`  \n",
    "\n",
    "__1.__ `ls -al`  \n",
    "\n",
    "This should show  2 files `directory_structure2.png` `directory_structure.png` and 2 directories `Pfalciparum`  `Styphi`.\n",
    "\n",
    "__2.__ There are 3 files in the directory (`Styphi.fa`, `Styphi.gff` and `Styphi.noseq.gff`). You can use `ls -l` to look inside the directory. This will show you which of the contents are files and which are directories. Don't forget to also include the `-a` option to show any hidden files:  \n",
    "   \n",
    "`ls -al Styphi`  \n",
    "  \n",
    "__3.__ There is 1 file in the directory called `Pfalciparum.bed` (and 2 subdirectories). You can use `ls -l` to look inside the directory. This will show you which of the contents are files and which are directories. Don't forget to also include the `-a` option to show any hidden files:  \n",
    "\n",
    "`ls -al Pfalciparum`  \n",
    "\n",
    "__4.__ There are 7 GFFs in the linux directory. To search from the linux directory, you can either use `cd` to move up to the directory, or you can specify the path in the `find` command. This can either be the absolute path, which you can get from `pwd`, or you can use the relative path, like so:  \n",
    "   \n",
    "`find ../.. -name *.gff`\n",
    "  \n",
    "__5.__ There are 7 fasta files in the linux directory. Note that fasta files normally end with `.fa` OR `.fasta`, so we need to make sure we look for both of these, by adding a wildcard (*) after `fa`:   \n",
    "   \n",
    "`find ../.. -name *.fa*`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The commands `grep` and `awk`\n",
    "\n",
    "##\n",
    "###\n",
    "###\n",
    "###\n",
    "###\n",
    "### Exercises\n",
    "\n",
    "Navigate to the linux/data/grep directory with:\n",
    "\n",
    "`cd ~/course_data/linux/data/grep`  \n",
    "\n",
    "__1.__ `grep \"^>\" exercises.fasta`\n",
    "\n",
    "Fasta sequences contain two lines per sequence (a header and then the corresponding sequence). All FASTA headers start with > so we search using ^> which means get me all lines which start with (^) a greater than symbol (>). This will look something like:\n",
    "\n",
    "```\n",
    ">sequence1 \n",
    ">Sequence2 \n",
    ">thing3 \n",
    ">Read4 \n",
    "```\n",
    "  \n",
    "__2.__ There are 1000 sequences. We use -c to count the number of matches:  \n",
    "  \n",
    "`grep -c \"^>\" exercises.fasta`  \n",
    "  \n",
    "Or pipe into wc:\n",
    "  \n",
    "`grep \"^>\" exercises.fasta | wc -l`  \n",
    "    \n",
    "__3.__ Yes, three of them:  \n",
    "\n",
    "```\n",
    ">sequence27 spaces in the name\n",
    ">sequence52 another with spaces\n",
    ">sequence412 yet another with spaces\n",
    "```\n",
    "One option is two greps piped together:  \n",
    "   \n",
    "`grep \"^>\" exercises.fasta | grep \" \"`  \n",
    "\n",
    "Here we look for lines which start with (^) a greater than symbol (>) and then look for any of these lines that contain the space character. \n",
    "\n",
    "Alternatively, we can do this with one regular expression:  \n",
    "   \n",
    "`grep \"^>.* .*\" exercises.fasta`  \n",
    "\n",
    "Here we look for lines which start with (^) a greater than symbol (>) followed by zero or more (*) of any characters (.) followed by a space followed by zero or more of any characters.\n",
    "\n",
    "__4.__ `grep -v \"^>\" exercises.fasta`   \n",
    "\n",
    "We use the -v option which is for inverse matching or returning everything that does not match the pattern we have here in quotes. So in the quotes we are asking for all sequences that begin with ‘>’ but by using -v we are asking for all sequences which do not start with >.\n",
    "   \n",
    "__5.__ Three. \n",
    "   \n",
    "`grep -v \"^>\" exercises.fasta | grep -c -i n`  \n",
    "\n",
    "Here we use the same command as before to get only the sequences (not the headers). We assume that ‘n’ is either ‘N’ or ‘n’ (i.e. upper or lower case). We could search individually for each of those, but to make it easier we do it in one command with -i which means the pattern search should be case insensitive. We use -c to count the number of matches.\n",
    "\n",
    "__6.__ Yes, one sequence. Try:   \n",
    "  \n",
    "`grep -v \"^>\" exercises.fasta | grep -i -v \"^[acgtn].*$\"`  \n",
    "\n",
    "Here we use the same command as before to get only the sequences (not the headers).\n",
    "\n",
    "Alternatively: \n",
    "  \n",
    "`grep -v \"^>\" exercises.fasta | grep -i \"[^ACGTN]\"`  \n",
    "\n",
    "Here we use the same command as before to get only the sequences (not the headers). Then we use grep with the ^ symbol to ask for matches NOT in the alphabet [acgtn] .\n",
    "  \n",
    "__7.__ 66 sequences. Try:  \n",
    "  \n",
    "`grep -v \"^>\" exercises.fasta | grep -c \"GC[AT]GC\"`  \n",
    "\n",
    "Here we use the same command as before to get only the sequences (not the headers). We use -c to count the number of matches to the strings GCAGC and GCTGC.\n",
    "\n",
    "__8.__ We found the total number of sequences earlier:  \n",
    "    \n",
    "`grep -c \"^>\" exercises.fasta`\n",
    "  \n",
    "... which outputs 1000  \n",
    "  \n",
    "To find the number of unique sequence names:  \n",
    "  \n",
    "`grep \"^>\" exercises.fasta | sort | uniq | wc -l`  \n",
    "  \n",
    "... which outputs 999.  \n",
    "  \n",
    "Therefore there is 1000 - 999 = 1 name duplicated.  \n",
    "\n",
    "If you want to see which one is duplicated you can use the -c option to tell us the number of times each sequence occurs. Here awk is used to determie which of the counts (first column or $1 is greater than 1 (i.e. is present more than once):\n",
    "\n",
    "`grep \"^>\" exercises.fasta | sort | uniq -c | awk '$1 > 1'`\n",
    "\n",
    "This gives:\n",
    "\n",
    "2 >sequence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "###\n",
    "###\n",
    "### Exercises\n",
    "\n",
    "Navigate to the linux/data/awk directory with:\n",
    "\n",
    "`cd ~/course_data/linux/data/awk` \n",
    "\n",
    "__1.__ Try:  \n",
    "  \n",
    "`awk -F\"\\t\" '{print $1}' exercises.bed | sort -u`  \n",
    "\n",
    "Here we use awk to split the file exercises.bed into individual columns and use `-F\"\\t\"` to indicate the columns are to be sperated based on the tab character. We print the first column (denoted by $1) which will be sequence name) and pipe this output to the `sort -u` command which will sort the list of sequence names and -u will select only the unique values from the list.\n",
    "\n",
    "This should give you:  \n",
    "\n",
    "```\n",
    "contig-1\n",
    "contig-3\n",
    "contig-4\n",
    "contig-5\n",
    "scaffold-2\n",
    "```\n",
    "  \n",
    "__2.__ There are 5 contigs.   \n",
    "   \n",
    "`awk -F\"\\t\" '{print $1}' exercises.bed | sort -u | wc -l`  \n",
    "  \n",
    "Here we use the command from the previous exercise to get the list of unique sequence names and count the number of lines with `wc`.  \n",
    "  \n",
    "__3.__ There are 164 features on the positive strand. Try:  \n",
    "   \n",
    "`awk -F\"\\t\" '$6==\"+\"' exercises.bed | wc -l`  \n",
    "   \n",
    "__4.__ There are 124 features on the negative strand. Try:  \n",
    "   \n",
    "`awk -F\"\\t\" '$6==\"-\"' exercises.bed | wc -l`  \n",
    "   \n",
    "__5.__ There are 33 repeats. Try:\n",
    "  \n",
    "`awk -F\"\\t\" '$4 ~ /repeat/' exercises.bed | wc -l`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Linux\n",
    "\n",
    "No exercises in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASH scripting\n",
    "\n",
    "##\n",
    "##\n",
    "##\n",
    "## Exercises\n",
    "\n",
    "__1.__ Here is an example of what this script could look like:\n",
    "```\n",
    "#!/usr/bin/env bash\n",
    "set -e\n",
    "\n",
    "# check that the correct number of options was given.\n",
    "# If not, then write a message explaining how to use the\n",
    "# script, and then exit.\n",
    "if [ $# -ne 1 ]\n",
    "then\n",
    "    echo \"usage: example_1.sh filename\"\n",
    "    echo\n",
    "    echo \"Prints the number of lines in the file\"\n",
    "    exit\n",
    "fi\n",
    "\n",
    "# Use sensibly named variable\n",
    "filename=$1\n",
    "\n",
    "# check if the input file exists\n",
    "if [ ! -f $filename ]\n",
    "then\n",
    "    echo \"File '$filename' not found! Cannot continue\"\n",
    "    exit\n",
    "fi\n",
    "\n",
    "\n",
    "# If still here, we can count the number of lines\n",
    "number_of_lines=$(wc -l $filename | awk '{print $1}')\n",
    "echo \"There are $number_of_lines lines in the file $filename\"\n",
    "```\n",
    "   \n",
    "__2.__ Here is an example of what this script could look like:\n",
    "```\n",
    "#!/usr/bin/env bash\n",
    "set -e\n",
    "for filename in ../scripts/loop_files/*; do ./exercise_1.sh $filename; done\n",
    "```\n",
    "\n",
    "__3.__ Here is an example of what this script could look like:\n",
    "```\n",
    "#!/usr/bin/env bash\n",
    "set -e\n",
    "\n",
    "# Check if the right number of options given.\n",
    "# If not, print the usage\n",
    "if [ $# -ne 1 ]\n",
    "    then\n",
    "        echo \"usage: example_3.sh in.gff\"\n",
    "        echo\n",
    "        echo \"Gathers some summary information from a gff file\"\n",
    "        exit\n",
    "fi\n",
    "\n",
    "# store the filename in a better named variable\n",
    "infile=$1\n",
    "\n",
    "\n",
    "# Stop if the input file does not exist\n",
    "if [ ! -f $infile ]\n",
    "then\n",
    "    echo \"File '$infile' not found! Cannot continue\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Gathering data for $infile...\"\n",
    "\n",
    "\n",
    "# Gather various stats on the file...\n",
    "\n",
    "\n",
    "# Total number of lines/records in file\n",
    "total_records=$(wc -l $infile | awk '{print $1}')\n",
    "echo \"File has $total_records records in total\"\n",
    "\n",
    "\n",
    "# Get the sources from column 2.\n",
    "echo\n",
    "echo \"The sources in the file are:\"\n",
    "awk '{print $2}' $infile | sort -u\n",
    "\n",
    "\n",
    "# Count the sources\n",
    "echo\n",
    "echo \"Count of sources, sorted by most common\"\n",
    "awk '{print $2}' $infile | sort | uniq -c | sort -n\n",
    "\n",
    "\n",
    "# Count which features have no score\n",
    "echo\n",
    "echo \"Count of features that have no score\"\n",
    "awk '$6==\".\" {print $3}' $infile | sort | uniq -c\n",
    "\n",
    "\n",
    "# Find how many bad coords there are\n",
    "echo\n",
    "bad_coords=$(awk '$5 < $4' $infile | wc -l | awk '{print $1}')\n",
    "echo \"Records with bad coordinates: $bad_coords\"\n",
    "\n",
    "\n",
    "\n",
    "#_______________________________________________________________#\n",
    "#                                                               #\n",
    "#      WARNING: the following examples are more advanced!       #\n",
    "#_______________________________________________________________#\n",
    "\n",
    "# if there were records with bad coords, find the sources responsible\n",
    "if [ $bad_coords != 0 ]\n",
    "then\n",
    "    echo\n",
    "    echo \"Sources of bad coordinates:\"\n",
    "    # Instead getting one source per line, pipe into awk again to print them\n",
    "    # on one line with semicolon and space between the names\n",
    "    awk '$5 < $4 {print $2}' $infile | sort -u | awk '{sources=sources\"; \"$1} END{print substr(sources, 3)}'\n",
    "fi\n",
    "\n",
    "\n",
    "\n",
    "# Count of the features. Instead of using awk .... |sort | uniq -c\n",
    "# we will just use awk. Compare this with the above method\n",
    "# used to count the sources. Although it is a longer command, it is more efficient\n",
    "echo\n",
    "echo \"Count of each feature:\"\n",
    "awk '{counts[$3]++} END{for (feature in counts){print feature\"\\t\"counts[feature]}}' $infile | sort -k2n\n",
    "\n",
    "\n",
    "# This example is even more complicated! It uses a loop to\n",
    "# get the mean score of the genes, broken down by source.\n",
    "echo\n",
    "echo \"Getting mean scores for each source...\"\n",
    "for source in `awk '{print $2}' $infile | sort | uniq`\n",
    "do\n",
    "    awk -v s=$source '$2==s {total+=$6; count++} END{print \"Mean score for\", s\":\\t\", total/count}' $infile\n",
    "done\n",
    "\n",
    "\n",
    "# We can use awk to split the input into multiple output files.\n",
    "# Writing print \"line\" > filename will append the string \"line\"\n",
    "# to a file called filename. If a file called filename\n",
    "# does not exist already, then it will be created.\n",
    "#\n",
    "# Write a new gff for each of the sources in the original input gff file\n",
    "echo\n",
    "echo \"Writing a file per source of the original gff file $infile to files called split.*\"\n",
    "awk '{filename=\"split.\"$2\".gff\"; print $0 > filename}' $infile\n",
    "echo \" ... done!\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
